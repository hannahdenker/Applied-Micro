<head>
  <link rel="stylesheet" type="text/css" href="stmarkdown.css">
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
</script>
<script type="text/javascript">
document.addEventListener('DOMContentLoaded', function() {
    htmlTableOfContents();
} );                        

function htmlTableOfContents( documentRef ) {
    var documentRef = documentRef || document;
    var toc = documentRef.getElementById("toc");
//  Use headings inside <article> only:
//  var headings = [].slice.call(documentRef.body.querySelectorAll('article h1, article h2, article h3, article h4, article h5, article h6'));
    var headings = [].slice.call(documentRef.body.querySelectorAll('h1, h2, h3, h4, h5, h6'));
    headings.forEach(function (heading, index) {
        var ref = "toc" + index;
        if ( heading.hasAttribute( "id" ) ) 
            ref = heading.getAttribute( "id" );
        else
            heading.setAttribute( "id", ref );

        var link = documentRef.createElement( "a" );
        link.setAttribute( "href", "#"+ ref );
        link.textContent = heading.textContent;

        var div = documentRef.createElement( "div" );
        div.setAttribute( "class", heading.tagName.toLowerCase() );
        div.appendChild( link );
        toc.appendChild( div );
    });
}


try {
    module.exports = htmlTableOfContents;
} catch (e) {
    // module.exports is not defined
}
</script>
</head>
<h1><a href="#problem-set-5" id="problem-set-5">Problem Set 5</a></h1>
<p>Course: ECON 8848<br />
Author: Hannah Denker<br />
Collaborators: Michelle Doughty &amp; Dan Mangan<br />
Date: 11 Mar 2021</p>
<nav id="toc"><strong><font size="5">Table of Contents</font></strong></nav>
<h2><a href="#potential-outcomes-framework" id="potential-outcomes-framework">Potential Outcomes Framework</a></h2>
<pre><code>.         ***Set # of obs to 100,000
.         set obs  100000
number of observations (_N) was 0, now 100,000

.         set seed 123456

. 
.         ***For each individual, draw two potential outcomes representing knowledge of micro in treated 
&gt; y_1 and untreated y_0 states of the world.
.         cap drop y0 

.         cap drop y1 

.         cap drop effect 

.         generate y0 = rnormal(50, 5) // untreated outcome has mean of 50 with sd of 5

.         generate y1 = y0 + rnormal(5, 2) // treated outcome will be equal to the untreated outcome +/- 
&gt; some amount where the mean of the amount is 5 an the sd=2

. 
.         ***Create var that is each individual's effect of having to take prelim second time. 
.         generate effect = y1 - y0 // treated outcome - untreated outcome

</code></pre>
<h3><a href="#selection-bias" id="selection-bias">Selection Bias</a></h3>
<p><strong>If you could observe both potential outcomes for each individual, what would you do?</strong><br />
To observe the potential outcomes for each individual, we would want to create a new variable in our dataset that would be the difference between the treated and untreated outcome for each individual. We&rsquo;ve done this in the creation of the &ldquo;effect&rdquo; variable above. We can then find the mean of this variable to identify the average causal effect across the sample.</p>
<p><strong>Does it match what you expected?</strong></p>
<pre><code>.         qui sum effect, meanonly

.         di in red `r(mean)'
5.0025634

</code></pre>
<p>The mean of the &ldquo;effect&rdquo; variable is 5.003. We would expect that this value <em>would</em> be close to 5 since the mean of the &lsquo;noise&rsquo; we added in the creation of the treated potential outcome equals 5.</p>
<p>Mimic the random assignment that would occur in an experiment.</p>
<pre><code>.         ***Create var that has a 0.5 prob of being 1 and is 0 otherwise
.         set seed 123456

.         cap drop treated

.         generate treated = runiform() &gt; 0.5

. 
.         ***Create a var that is the observed potential outcome for each individual based on group assig
&gt; nment. 
.         cap drop obs_y

.         generate obs_y = y0

.         replace  obs_y = y1 if treated == 1
(50,079 real changes made)

. 
.         ***Run a reg. to get the difference in means of the observed value of y_i between treated/untre
&gt; ated groups.
.         regr obs_y treated, robust

Linear regression                               Number of obs     =    100,000
                                                F(1, 99998)       =   23669.21
                                                Prob &gt; F          =     0.0000
                                                R-squared         =     0.1914
                                                Root MSE          =     5.2017

------------------------------------------------------------------------------
             |               Robust
       obs_y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     treated |   5.060769   .0328946   153.85   0.000     4.996296    5.125242
       _cons |   49.98398   .0224287  2228.57   0.000     49.94002    50.02794
------------------------------------------------------------------------------

.         disp in red _b[treated] //coef. of interest is on treated
5.0607689

</code></pre>
<p><strong>Does this regression coefficient match the true ATE?</strong><br />
The coefficient on the treated dummy is 4.9498, with a standard error of 0.033. We would conclude that this estimate captures the true ATE within its estimated confidence interval.</p>
<p>Now, mimic the assignment that would occur if assignment to the treatment were based on an exam.</p>
<pre><code>.         cap drop firstprelim 

.         cap drop failed 

.         cap drop secondprelim 

.         cap drop yobs_2

. 
.         ***Create a score on the first prelim equal to person's actual knowledge level (y_0) and some n
&gt; oise. 
.         cap drop firstprelim

.         generate firstprelim = y0 + rnormal(0, 2)

. 
.         ***Create a new treatment variable equal to 1 iff i's exam score is &lt; 45.
.         cap drop failed

.         generate failed = (firstprelim &lt; 45)

. 
.         ***Create new observed y var = to potential outcome under assignment into groups via test score
&gt; . 
.                 **First make a secondprelim score using the first prelim score with additional noise. 
.                 cap drop secondprelim

.                 generate secondprelim = y1 + rnormal(0,2)

. 
.                 cap drop obs_y2

.                 generate obs_y2 = firstprelim

.                 replace  obs_y2 = secondprelim if failed == 1
(17,697 real changes made)

</code></pre>
<p><strong>What is the sign of the selection bias introduced by this assignment procedure?</strong><br />
When we use the score from taking the preliminary exam the first time to assign students into treatment or control groups, we see that negative selection bias is introduced. This results from assigning a second prelim score to students who earned &ldquo;bad&rdquo; scores on the first prelim, which leads to smaller y1 scores as well (since y1 scores are a function of y0 scores). We have altered the sample in a way that creates a group of students with higher y0 scores and a group with lower y0 scores, and this difference will also be captured in the effect of taking the prelim twice.</p>
<p><strong>What is the exact magnitude of the selection bias in your sample?</strong></p>
<pre><code>.         ***Selection Bias = Expected value of y0 for treated - expected value of y0 for untreated shoul
&gt; d be the ATE
.                 
.                 **Expected value of y0 for treated
.                 sum obs_y2 if failed==1 

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
      obs_y2 |     17,697    48.18611     3.98883   29.22013   62.14917

.                 loc treated_mean = `r(mean)'

. 
.                 **Expected value of y0 for untreated 
.                 sum obs_y2 if failed==0 

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
      obs_y2 |     82,303    51.71573    4.198857   45.00004   73.10788

.                 loc untreated_mean = `r(mean)'

. 
.                 **Selection Bias
.                 di in red `treated_mean'-`untreated_mean'
-3.5296237

</code></pre>
<p>The magnitude of selection bias in our sample equals -3.53.</p>
<p>Run a regression to estimate the difference in observed outcomes between treated and untreated groups.</p>
<pre><code>.         regr obs_y2 failed, robust

Linear regression                               Number of obs     =    100,000
                                                F(1, 99998)       =   11190.90
                                                Prob &gt; F          =     0.0000
                                                R-squared         =     0.0948
                                                Root MSE          =     4.1625

------------------------------------------------------------------------------
             |               Robust
      obs_y2 |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      failed |  -3.529624   .0333654  -105.79   0.000    -3.595019   -3.464228
       _cons |   51.71573   .0146361  3533.44   0.000     51.68705    51.74442
------------------------------------------------------------------------------

.         disp in red _b[failed]
-3.5296237

</code></pre>
<p><strong>Is the resulting coefficient what you expected, given your answer to the above questions and our formula from class?</strong><br />
Yes. We see that failing the first prelim (failed=1) is associated with a -3.72 point difference in observed scores that were set equal to potential outcomes assigned based on the outcome of the first exam. This is the exact value we found when we calculated the difference between the treated and untreated means by hand.</p>
<h3><a href="#ate-vs-tot" id="ate-vs-tot">ATE vs TOT</a></h3>
<p>Suppose now that people know their own treatment eﬀects, and that they are allowed to enter the treatment endogenously. Suppose further that the costs of getting the treatment vary from person to person, but that they are distributed N(−5, 4) and that they are independent of the treated and untreated outcomes. Thus, on average, people are indiﬀerent to receiving the treatment. Create a variable containing each individual’s cost.</p>
<pre><code>.         ***Creating var to represent variable cost of treatment. 
.         cap drop cost 

.         generate cost = rnormal(-5, 2)

. 
.         ***Specifically, assume that those people whose net benefit (treatment effect minus cost) choos
&gt; e to receive the treatment.  
.         cap drop treated3 

.         generate treated3 = 0

.         replace  treated3 = 1 if y1 - y0 - cost &gt; 0
(99,978 real changes made)

. 
.         twoway (scatter cost treated3) ///
&gt;                    (lfit cost treated3)

.         
.         ***Create a new observed value of y based on this endogenous assignment mechanism.
.         cap drop obs_y3 

.         generate obs_y3 = obs_y2

.         replace  obs_y3 = y1 if treated3 == 1
(99,978 real changes made)

. 
.         **Expected value of y0 for treated
.         sum obs_y3 if treated3==1 

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
      obs_y3 |     99,978    55.01605    5.391469   30.12358   76.72649

.         loc treated_mean = `r(mean)'

. 
.         **Expected value of y0 for untreated 
.         sum obs_y3 if treated3==0 

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
      obs_y3 |         22    49.51476    7.222297   36.03545   61.37553

.         loc untreated_mean = `r(mean)'

. 
.         **Selection Bias
.         di in red `treated_mean'-`untreated_mean'
5.5012861

. 
</code></pre>
<p>Does this assignment mechanism create selection bias? Why or why not?</p>
<p>Run a regression to estimate the diﬀerence in observed y between the two groups.</p>
<pre><code>.         regr obs_y3 treated3, robust

Linear regression                               Number of obs     =    100,000
                                                F(1, 99998)       =      13.37
                                                Prob &gt; F          =     0.0003
                                                R-squared         =     0.0002
                                                Root MSE          =     5.3919

------------------------------------------------------------------------------
             |               Robust
      obs_y3 |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    treated3 |   5.501286   1.504508     3.66   0.000     2.552468    8.450104
       _cons |   49.51476   1.504412    32.91   0.000     46.56613    52.46339
------------------------------------------------------------------------------

.         disp in red _b[treated3]
5.5012861

</code></pre>
<p>Based on your answer to the above question, does this regression have a causal interpretation?</p>
<p>Calculate the true TOT for this sample.</p>
<pre><code>. 
.         summ effect if treated3 == 1, meanonly

.         disp in red  `r(mean)'
5.0036298

. 
</code></pre>
<p>Is this number consistent with your argument for or against a causal interpretation in the previous regression?</p>
<h3><a href="#omitted-variable-bias" id="omitted-variable-bias">Omitted Variable Bias</a></h3>
<p>Bivariate vs. Multivariate Regression</p>
<p>Run a regression of &ldquo;read4&rdquo; on &ldquo;exppp&rdquo;.</p>
<p>Interpret the regression, including the magnitude. Doing so may require calculating some descriptive statistics and carefully reading variable labels.</p>
<p>Without additional controls, it is unlikely that this regression has a causal interpretation. Suppose that you are considering adding a control variable in the hopes of more closely approximating a regression speciﬁcation for which you could invoke the CIA. In particular, consider &ldquo;lunch&rdquo;, or the percent of the school’s students who are eligible for the federal free lunch program. Eligible students come from families with relatively low incomes.</p>
<p>What do you think is the likely sign on the coeﬃcient for &ldquo;lunch&rdquo; if you were to include it in the above regression. Why?</p>
<p>Given your answer above, what do you expect to be the sign of the omitted variable bias in your bivariate speciﬁcation? Why? Be precise with your answer, including the expected sign of other relevant correlations.</p>
<p>Run the speciﬁcation that includes &ldquo;lunch&rdquo; as an additional control variable.</p>
<p>Did the addition of the &ldquo;lunch&rdquo; variable change the coeﬃcient on the &ldquo;exppp&rdquo; variable in the way you expected? What have you learned about the (sample) correlation between expenditure per pupil and the percent of students who are eligible for the free lunch program?</p>
<p>What is your best guess of the magnitude of the omitted variable bias simply by comparing these two regressions?</p>
<p>Calculate the omitted variable bias using the formula discussed in the notes. You will need to run an auxiliary regression.</p>
<p>Were you able to get the same omitted variable bias that you saw by running the bivariate and multivariate regressions?</p>
<pre><code>. 
.         use &quot;${datapath}schoolexp.dta&quot;, replace

.         reg read4 exppp, robust

Linear regression                               Number of obs     =      1,823
                                                F(1, 1821)        =       1.44
                                                Prob &gt; F          =     0.2302
                                                R-squared         =     0.0010
                                                Root MSE          =     19.143

------------------------------------------------------------------------------
             |               Robust
       read4 |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       exppp |  -.0005458   .0004547    -1.20   0.230    -.0014377    .0003461
       _cons |   62.89736   2.333356    26.96   0.000     58.32103     67.4737
------------------------------------------------------------------------------

. 
</code></pre>
<pre><code>. 
.         reg read4 exppp lunch, robust

Linear regression                               Number of obs     =      1,823
                                                F(2, 1820)        =     423.22
                                                Prob &gt; F          =     0.0000
                                                R-squared         =     0.3868
                                                Root MSE          =     15.002

------------------------------------------------------------------------------
             |               Robust
       read4 |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       exppp |    .002063   .0003702     5.57   0.000      .001337     .002789
       lunch |  -.4629633    .015944   -29.04   0.000    -.4942337   -.4316928
       _cons |   67.51695   1.858993    36.32   0.000     63.87096    71.16293
------------------------------------------------------------------------------

. 
</code></pre>
<pre><code>. 
.         reg read4 exppp lunch, robust

Linear regression                               Number of obs     =      1,823
                                                F(2, 1820)        =     423.22
                                                Prob &gt; F          =     0.0000
                                                R-squared         =     0.3868
                                                Root MSE          =     15.002

------------------------------------------------------------------------------
             |               Robust
       read4 |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       exppp |    .002063   .0003702     5.57   0.000      .001337     .002789
       lunch |  -.4629633    .015944   -29.04   0.000    -.4942337   -.4316928
       _cons |   67.51695   1.858993    36.32   0.000     63.87096    71.16293
------------------------------------------------------------------------------

.         global beta1cor = _b[exppp]

.         global beta2cor = _b[lunch]

. 
.         reg read4 exppp

      Source |       SS           df       MS      Number of obs   =     1,823
-------------+----------------------------------   F(1, 1821)      =      1.77
       Model |  647.160324         1  647.160324   Prob &gt; F        =    0.1840
    Residual |  667332.262     1,821  366.464724   R-squared       =    0.0010
-------------+----------------------------------   Adj R-squared   =    0.0004
       Total |  667979.422     1,822  366.618783   Root MSE        =    19.143

------------------------------------------------------------------------------
       read4 |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       exppp |  -.0005458   .0004107    -1.33   0.184    -.0013514    .0002597
       _cons |   62.89736   2.180318    28.85   0.000     58.62117    67.17355
------------------------------------------------------------------------------

.         disp _b[exppp] - $beta1cor
-.00260885

. 
.         reg lunch exppp

      Source |       SS           df       MS      Number of obs   =     1,823
-------------+----------------------------------   F(1, 1821)      =    104.46
       Model |  68977.8563         1  68977.8563   Prob &gt; F        =    0.0000
    Residual |  1202491.94     1,821   660.34703   R-squared       =    0.0543
-------------+----------------------------------   Adj R-squared   =    0.0537
       Total |   1271469.8     1,822  697.842919   Root MSE        =    25.697

------------------------------------------------------------------------------
       lunch |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       exppp |   .0056351   .0005514    10.22   0.000     .0045537    .0067165
       _cons |   9.978296   2.926778     3.41   0.001     4.238102    15.71849
------------------------------------------------------------------------------

.         disp _b[exppp] * $beta2cor
-.00260885

. 
</code></pre>
<h3><a href="#fwl" id="fwl">FWL</a></h3>
<p>Use the decomposition suggested by FWL to calculate the coeﬃcient on “exppp” in the multi-variate regression.</p>
<p>Check that the coeﬃcient is the same and that the two sets of residuals are identical as the theorem suggests.</p>
<p>Create two scatter plots of the data used to identify the coeﬃcient on exppp, one for the bivariate regression, and one for the transformed data that went into your ﬁnal regression using the FWL method. Save each one into your workspace.</p>
<p>Use the &ldquo;graph combine&rdquo; command to put these graphs into one ﬁgure. Export a copy of this graph to a graphics format (e.g. pdf, png, etc.) and include a copy with your submission.</p>
<p>Explain the diﬀerence in what the variation in these two scatter plots represents. In particular, what does it mean for a school to be above or below the mean of the x-variable in each plot?</p>
<p>Do you think that you would be justiﬁed in applying the CIA to the regression that includes both &ldquo;exppp&rdquo; and &ldquo;lunch&rdquo;? In other words, can you call the estimated coeﬃcient the causal eﬀect of spending another dollar on test scores? If not, list two potential omitted variables and sign the bias of each. If you think you would be justiﬁed, list two potential omitted variables and argue why the bias would be zero.</p>
<pre><code>. 
.         reg read4 lunch, robust

Linear regression                               Number of obs     =      1,823
                                                F(1, 1821)        =     828.01
                                                Prob &gt; F          =     0.0000
                                                R-squared         =     0.3737
                                                Root MSE          =     15.157

------------------------------------------------------------------------------
             |               Robust
       read4 |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       lunch |  -.4431021   .0153987   -28.78   0.000    -.4733031   -.4129011
       _cons |   77.45448    .547038   141.59   0.000     76.38159    78.52736
------------------------------------------------------------------------------

.         predict read4_resids, residuals

.         label variable read4_resids &quot;Residualized Student Reading Score (%)&quot;

. 
.         reg exppp lunch, robust

Linear regression                               Number of obs     =      1,823
                                                F(1, 1821)        =      96.28
                                                Prob &gt; F          =     0.0000
                                                R-squared         =     0.0543
                                                Root MSE          =     1062.2

------------------------------------------------------------------------------
             |               Robust
       exppp |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       lunch |   9.627238   .9811534     9.81   0.000     7.702934    11.55154
       _cons |   4816.978   44.57753   108.06   0.000      4729.55    4904.407
------------------------------------------------------------------------------

.         predict exppp_resids, residuals

.         label variable exppp_resids &quot;Residualized Expenditure per pupil&quot;

. 
.         reg read4_resids exppp_resids

      Source |       SS           df       MS      Number of obs   =     1,823
-------------+----------------------------------   F(1, 1821)      =     38.87
       Model |  8743.58554         1  8743.58554   Prob &gt; F        =    0.0000
    Residual |  409596.145     1,821  224.929239   R-squared       =    0.0209
-------------+----------------------------------   Adj R-squared   =    0.0204
       Total |   418339.73     1,822  229.604682   Root MSE        =    14.998

------------------------------------------------------------------------------
read4_resids |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
exppp_resids |    .002063   .0003309     6.23   0.000     .0014141     .002712
       _cons |   7.91e-09   .3512607     0.00   1.000    -.6889163    .6889163
------------------------------------------------------------------------------

. 
.         scatter read4 exppp //, scheme(s2mono)

.         graph save bivariate.gph, replace
(file bivariate.gph saved)

.         scatter read4_resids exppp_resids //, scheme(s2mono)

.         graph save fwl.gph, replace
(file fwl.gph saved)

. 
.         graph combine bivariate.gph fwl.gph

.         graph save combined_graph.gph, replace
(file combined_graph.gph saved)

. 
</code></pre>
<h3><a href="#signing-the-bias" id="signing-the-bias">Signing the Bias</a></h3>
<p>For each of these regressions, select an additional variable that you believe would need to be included in a multi-variate regression in order to estimate a causal parameter. Describe what you expect the sign of the omitted variable bias to be (positive, negative, or zero). Show your work, i.e. spell out the full argument for your answer.</p>
<p>A bivariate regression of birthweight on mother’s daily smoking.</p>
<p>A bivariate regression of patient’s subjective health on health insurance coverage.</p>
<p>A bivariate regression of age at which a young woman becomes sexually active on whether she eats breakfast in the morning.</p>
<h3><a href="#matching" id="matching">Matching</a></h3>
<p>For this section, use the &ldquo;matching ps5.dta&rdquo; data available on D2L.</p>
<p>These data have been constructed to satisfy the CIA. Treatment is not randomly assigned unconditionally, but treatment is randomly assigned conditional on gender. These data have been simulated, and thus they include both potential outcomes.</p>
<p>What is the true ATE for women?</p>
<p>What is the true ATE for men?</p>
<p>What is the overall ATE for the sample?</p>
<p>What fraction of each gender received the treatment?</p>
<p>Does this assignment mechanism create selection bias? How do you know?</p>
<p>HINT: You may want to use an additional command to calculate this.</p>
<p>Run a regression of &ldquo;yobs&rdquo; on &ldquo;treated&rdquo;. Does this regression identify a causal eﬀect? Why or why not?</p>
<p>Run the same regression separately on the male and female subsamples. Do these regressions have a causal interpretation?</p>
<p>Run an interaction model to get the results of these two regressions in a single regression. Interpret each of the coeﬃcients. Explain how you could use the results of this regression to estimate both the ATE and the TOT. You may ignore the question of how you would properly calculate standard errors on these treatment eﬀects.</p>
<p>Now run a regression of “yobs” on “treated” and “female”. Does this regression have a causal interpretation? If so, which kind of treatment eﬀect? Defend your answer, paying attention to all of the necessary assumptions that we discussed in class.</p>
<p>Now use the “psmatch2” command to use matching to identify the various treatment eﬀects. Begin by using radius matching with a caliper of 0.5. Include the option to calculate both the ATE and the ATT/TOT. Does this matching mechanism lead to the results you expected? Explain why or why not?</p>
<p>Re-run the matching estimator using a smaller bandwith (e.g. 0.1). Explain how this smaller bandwidth allows you to get more reasonable results.</p>
<pre><code>. 
.         use &quot;${datapath}matching_ps5.dta&quot;, clear

. 
.         gen te = y1 - y0

.         mean te if female == 1

Mean estimation                   Number of obs   =      2,555

--------------------------------------------------------------
             |       Mean   Std. Err.     [95% Conf. Interval]
-------------+------------------------------------------------
          te |          5   1.41e-09             5           5
--------------------------------------------------------------

.         mean te if female == 0

Mean estimation                   Number of obs   =      2,445

--------------------------------------------------------------
             |       Mean   Std. Err.     [95% Conf. Interval]
-------------+------------------------------------------------
          te |         10   1.31e-08            10          10
--------------------------------------------------------------

.         mean te

Mean estimation                   Number of obs   =      5,000

--------------------------------------------------------------
             |       Mean   Std. Err.     [95% Conf. Interval]
-------------+------------------------------------------------
          te |      7.445   .0353503      7.375698    7.514302
--------------------------------------------------------------

.         bysort female: sum treated

---------------------------------------------------------------------------------------------------------
-&gt; female = 0

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
     treated |      2,445    .7443763    .4363005          0          1

---------------------------------------------------------------------------------------------------------
-&gt; female = 1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
     treated |      2,555    .2626223     .440145          0          1


. 
</code></pre>
<pre><code>. 
.         sort female

.         bysort female: sum y0 y1

---------------------------------------------------------------------------------------------------------
-&gt; female = 0

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
          y0 |      2,445    10.02004     1.98157   3.185875   18.62902
          y1 |      2,445    20.02004     1.98157   13.18587   28.62902

---------------------------------------------------------------------------------------------------------
-&gt; female = 1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
          y0 |      2,555   -.0022972    2.056391  -7.606311   6.652541
          y1 |      2,555    4.997703    2.056391  -2.606311   11.65254


.         bysort female: compare yobs y1

---------------------------------------------------------------------------------------------------------
-&gt; female = 0

                                        ---------- difference ----------
                            count       minimum      average     maximum
------------------------------------------------------------------------
yobs&lt;y1                       625           -10          -10   -9.999999
yobs=y1                      1820
                       ----------
jointly defined              2445           -10    -2.556237           0
                       ----------
total                        2445

---------------------------------------------------------------------------------------------------------
-&gt; female = 1

                                        ---------- difference ----------
                            count       minimum      average     maximum
------------------------------------------------------------------------
yobs&lt;y1                      1884            -5           -5          -5
yobs=y1                       671
                       ----------
jointly defined              2555            -5    -3.686888           0
                       ----------
total                        2555

. 
</code></pre>
<pre><code>. 
.         reg yobs treated, robust

Linear regression                               Number of obs     =      5,000
                                                F(1, 4998)        =    6368.41
                                                Prob &gt; F          =     0.0000
                                                R-squared         =     0.5609
                                                Root MSE          =     5.9678

------------------------------------------------------------------------------
             |               Robust
        yobs |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     treated |   13.48758   .1690124    79.80   0.000     13.15624    13.81891
       _cons |   2.490117   .0957861    26.00   0.000     2.302334      2.6779
------------------------------------------------------------------------------

. 
</code></pre>
<pre><code>. 
.         bysort female: reg yobs treated, robust

---------------------------------------------------------------------------------------------------------
-&gt; female = 0

Linear regression                               Number of obs     =      2,445
                                                F(1, 2443)        =   12042.03
                                                Prob &gt; F          =     0.0000
                                                R-squared         =     0.8290
                                                Root MSE          =      1.982

------------------------------------------------------------------------------
             |               Robust
        yobs |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     treated |   10.00179   .0911439   109.74   0.000     9.823063    10.18052
       _cons |   10.01871   .0782983   127.96   0.000     9.865173    10.17225
------------------------------------------------------------------------------

---------------------------------------------------------------------------------------------------------
-&gt; female = 1

Linear regression                               Number of obs     =      2,555
                                                F(1, 2553)        =    3087.68
                                                Prob &gt; F          =     0.0000
                                                R-squared         =     0.5358
                                                Root MSE          =     2.0568

------------------------------------------------------------------------------
             |               Robust
        yobs |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     treated |   5.019529   .0903331    55.57   0.000     4.842395    5.196663
       _cons |  -.0074259   .0479795    -0.15   0.877    -.1015085    .0866567
------------------------------------------------------------------------------

. 
</code></pre>
<pre><code>. 
.         reg yobs treated##female, robust

Linear regression                               Number of obs     =      5,000
                                                F(3, 4996)        =   31199.45
                                                Prob &gt; F          =     0.0000
                                                R-squared         =     0.9497
                                                Root MSE          =     2.0205

--------------------------------------------------------------------------------
               |               Robust
          yobs |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
---------------+----------------------------------------------------------------
     1.treated |   10.00179   .0911431   109.74   0.000      9.82311    10.18047
      1.female |  -10.02614   .0918291  -109.18   0.000    -10.20616   -9.846111
               |
treated#female |
          1 1  |  -4.982261   .1283249   -38.83   0.000    -5.233835   -4.730688
               |
         _cons |   10.01871   .0782976   127.96   0.000     9.865213    10.17221
--------------------------------------------------------------------------------

. 
</code></pre>
<pre><code>. 
.         reg yobs treated female, robust

Linear regression                               Number of obs     =      5,000
                                                F(2, 4997)        =   41180.13
                                                Prob &gt; F          =     0.0000
                                                R-squared         =     0.9350
                                                Root MSE          =     2.2963

------------------------------------------------------------------------------
             |               Robust
        yobs |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     treated |   7.433993   .0828201    89.76   0.000     7.271629    7.596357
      female |  -12.57164    .082822  -151.79   0.000      -12.734   -12.40927
       _cons |   11.93012   .0826656   144.32   0.000     11.76806    12.09218
------------------------------------------------------------------------------

. 
</code></pre>
<pre><code>. 
.         psmatch2 treated female, outcome(yobs) caliper(0.5) ate

Probit regression                               Number of obs     =      5,000
                                                LR chi2(1)        =    1209.54
                                                Prob &gt; chi2       =     0.0000
Log likelihood =  -2860.933                     Pseudo R2         =     0.1745

------------------------------------------------------------------------------
     treated |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      female |  -1.292178   .0382861   -33.75   0.000    -1.367218   -1.217139
       _cons |   .6568965   .0274378    23.94   0.000     .6031194    .7106736
------------------------------------------------------------------------------
----------------------------------------------------------------------------------------
        Variable     Sample |    Treated     Controls   Difference         S.E.   T-stat
----------------------------+-----------------------------------------------------------
            yobs  Unmatched | 15.9776929   2.49011711   13.4875758   .168796854    79.90
                        ATT | 15.9776929   10.0223913   5.95530166   8.03580089     0.74
                        ATU | 2.49011711   9.68352807   7.19341097            .        .
                        ATE |                           6.57658491            .        .
----------------------------+-----------------------------------------------------------
Note: S.E. does not take into account that the propensity score is estimated.

           | psmatch2:
 psmatch2: |   Common
 Treatment |  support
assignment | On suppor |     Total
-----------+-----------+----------
 Untreated |     2,509 |     2,509 
   Treated |     2,491 |     2,491 
-----------+-----------+----------
     Total |     5,000 |     5,000 

.         disp in red &quot;ATE: &quot; r(ate) &quot;, ATT: &quot; r(att)
ATE: 6.5765849, ATT: 5.9553017

. 
</code></pre>
<pre><code>. 
.         psmatch2 treated female, outcome(yobs) caliper(0.1) ate

Probit regression                               Number of obs     =      5,000
                                                LR chi2(1)        =    1209.54
                                                Prob &gt; chi2       =     0.0000
Log likelihood =  -2860.933                     Pseudo R2         =     0.1745

------------------------------------------------------------------------------
     treated |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      female |  -1.292178   .0382861   -33.75   0.000    -1.367218   -1.217139
       _cons |   .6568965   .0274378    23.94   0.000     .6031194    .7106736
------------------------------------------------------------------------------
----------------------------------------------------------------------------------------
        Variable     Sample |    Treated     Controls   Difference         S.E.   T-stat
----------------------------+-----------------------------------------------------------
            yobs  Unmatched | 15.9776929   2.49011711   13.4875758   .168796854    79.90
                        ATT | 15.9776929   10.0223913   5.95530166   8.03580089     0.74
                        ATU | 2.49011711   9.68352807   7.19341097            .        .
                        ATE |                           6.57658491            .        .
----------------------------+-----------------------------------------------------------
Note: S.E. does not take into account that the propensity score is estimated.

           | psmatch2:
 psmatch2: |   Common
 Treatment |  support
assignment | On suppor |     Total
-----------+-----------+----------
 Untreated |     2,509 |     2,509 
   Treated |     2,491 |     2,491 
-----------+-----------+----------
     Total |     5,000 |     5,000 

.         disp &quot;ATE: &quot; r(ate) &quot;, ATT: &quot; r(att)
ATE: 6.5765849, ATT: 5.9553017

. 
</code></pre>
